# Issues #197, #147, #217 Implementation Design

**Date:** November 4, 2025
**Issues:** [#197](https://github.com/jukasdrj/books-tracker-v1/issues/197), [#147](https://github.com/jukasdrj/books-tracker-v1/issues/147), [#217](https://github.com/jukasdrj/books-tracker-v1/issues/217)
**Status:** Design Approved

## Executive Summary

This design addresses three high-impact performance and infrastructure issues:

1. **#197 (Backend):** Cache key normalization for 15-30% higher hit rates
2. **#147 (Backend):** Image proxy with R2 caching for 50%+ faster image loading
3. **#217 (iOS):** LibraryRepository performance optimizations (10x faster count queries)

**Execution Strategy:** Backend-first (#197 + #147 together), then iOS (#217)

**Total Effort:** 8-10 hours
- Backend work: 3-4 hours
- iOS work: 5-6 hours

## Architecture Overview

### Execution Order

**Phase 1: Backend Work (#197 + #147)**
- Single worktree: `../books-tracker-backend/`
- Shared normalization infrastructure for both issues
- Single deployment (cache invalidation + new image proxy)
- 3-4 hours development time

**Phase 2: iOS Work (#217)**
- Separate worktree: `../books-tracker-ios-perf/`
- After backend deployed (can test against production image proxy)
- 5-6 hours development time

**Rationale:**
- Backend changes deploy together (single cache invalidation window)
- iOS can validate against production backend (real cache behavior)
- Clear dependency: Image proxy must exist before iOS uses it
- No context switching between Swift and TypeScript mid-task

---

## Backend Design (#197 + #147)

### 1. Shared Normalization Infrastructure

**New File:** `cloudflare-workers/api-worker/src/utils/normalization.ts`

This utility provides consistent normalization across all cache keys, search logic, and image URLs.

#### Title Normalization
```typescript
/**
 * Normalizes book title for cache key generation and search matching
 * - Lowercase for case-insensitive matching
 * - Trim whitespace
 * - Remove leading articles (the, a, an) for better deduplication
 * - Remove punctuation for fuzzy matching
 */
export function normalizeTitle(title: string): string {
  return title
    .toLowerCase()
    .trim()
    .replace(/^(the|a|an)\s+/i, '')  // "The Hobbit" → "hobbit"
    .replace(/[^a-z0-9\s]/g, '');     // Remove punctuation
}
```

**Examples:**
- `"The Hobbit"` → `"hobbit"`
- `"  The Hobbit  "` → `"hobbit"`
- `"the hobbit"` → `"hobbit"`
- All three now share the same cache entry ✅

#### ISBN Normalization
```typescript
/**
 * Normalizes ISBN for cache key generation
 * - Remove hyphens (ISBN-10/ISBN-13 formatting)
 * - Trim whitespace
 * - Preserve digits and 'X' only (ISBN-10 check digit)
 */
export function normalizeISBN(isbn: string): string {
  return isbn.trim().replace(/[^0-9X]/gi, '');
}
```

**Examples:**
- `"978-0-547-92822-7"` → `"9780547928227"`
- `"978 0 547 92822 7"` → `"9780547928227"`
- `"9780547928227"` → `"9780547928227"`
- All three now share the same cache entry ✅

#### Author Normalization
```typescript
/**
 * Normalizes author name for cache matching
 * - Lowercase
 * - Trim whitespace
 */
export function normalizeAuthor(author: string): string {
  return author.toLowerCase().trim();
}
```

#### Image URL Normalization
```typescript
/**
 * Normalizes image URL for cache key generation
 * - Remove query parameters (tracking, sizing hints)
 * - Normalize protocol (http → https)
 * - Trim whitespace
 */
export function normalizeImageURL(url: string): string {
  try {
    const parsed = new URL(url.trim());
    // Remove query params (e.g., ?zoom=1, ?source=gbs_api)
    parsed.search = '';
    // Force HTTPS
    parsed.protocol = 'https:';
    return parsed.toString();
  } catch {
    // Invalid URL, return as-is
    return url.trim();
  }
}
```

**Examples:**
- `"http://books.google.com/covers/abc.jpg?zoom=1"` → `"https://books.google.com/covers/abc.jpg"`
- `"https://books.google.com/covers/abc.jpg"` → `"https://books.google.com/covers/abc.jpg"`
- Both share the same R2 cache entry ✅

### 2. Cache Key Normalization (#197)

**Integration Points:**

**File:** `src/handlers/v1/search-title.ts`
```typescript
import { normalizeTitle } from '../../utils/normalization.ts';

export async function handleSearchTitle(query: string, env: any) {
  const normalizedTitle = normalizeTitle(query);  // ← NEW
  const works = await enrichMultipleBooks(
    { title: normalizedTitle },  // ← Use normalized
    env,
    { maxResults: 20 }
  );
  // ... rest of handler
}
```

**File:** `src/handlers/v1/search-isbn.ts`
```typescript
import { normalizeISBN } from '../../utils/normalization.ts';

export async function handleSearchISBN(isbn: string, env: any) {
  const normalizedISBN = normalizeISBN(isbn);  // ← NEW
  // ... use normalizedISBN for enrichment
}
```

**File:** `src/handlers/v1/search-advanced.ts`
```typescript
import { normalizeTitle, normalizeAuthor } from '../../utils/normalization.ts';

export async function handleSearchAdvanced(title: string, author: string, env: any) {
  const normalizedTitle = title ? normalizeTitle(title) : undefined;  // ← NEW
  const normalizedAuthor = author ? normalizeAuthor(author) : undefined;  // ← NEW
  // ... use normalized values
}
```

**File:** `src/services/enrichment.ts`
```typescript
import { normalizeTitle, normalizeISBN } from '../utils/normalization.ts';

export async function enrichSingleBook(params, env) {
  // Normalize before generating cache key
  if (params.title) {
    params.title = normalizeTitle(params.title);  // ← NEW
  }
  if (params.isbn) {
    params.isbn = normalizeISBN(params.isbn);  // ← NEW
  }
  // ... rest of enrichment logic
}
```

**Expected Impact:**
- Current cache hit rate: ~60-70%
- Post-normalization: ~75-90%
- **Net improvement: +15-30% cache efficiency**
- Cost savings: ~$15/month (fewer Google Books API calls)

### 3. Image Proxy with R2 Caching (#147)

**New Endpoint:** `GET /images/proxy?url={imageUrl}&size={size}`

**Architecture Flow:**
```
1. iOS requests image: /images/proxy?url=https://books.google.com/covers/abc.jpg&size=medium
2. Worker normalizes URL → "https://books.google.com/covers/abc.jpg"
3. Generate cache key: SHA-256(normalized URL) → "covers/a3f2b1..."
4. Check R2 bucket (BOOK_COVERS):
   - HIT → Return from R2 with Cloudflare Image Resizing
   - MISS → Fetch from origin, store in R2, return resized image
5. Cloudflare edge cache handles subsequent requests (CDN layer)
```

**New File:** `cloudflare-workers/api-worker/src/handlers/image-proxy.ts`

```typescript
import { normalizeImageURL } from '../utils/normalization.ts';
import { createHash } from 'crypto';

/**
 * Proxies and caches book cover images via R2 + Cloudflare Image Resizing
 *
 * Flow:
 * 1. Normalize image URL for cache key
 * 2. Check R2 bucket for cached original
 * 3. If miss: Fetch from origin, store in R2
 * 4. Return image with Cloudflare Image Resizing (on-the-fly thumbnail)
 */
export async function handleImageProxy(request: Request, env: any): Promise<Response> {
  const url = new URL(request.url);
  const imageUrl = url.searchParams.get('url');
  const size = url.searchParams.get('size') || 'medium'; // small, medium, large

  // Validation
  if (!imageUrl) {
    return new Response('Missing url parameter', { status: 400 });
  }

  // Security: Only allow known book cover domains
  const allowedDomains = [
    'books.google.com',
    'covers.openlibrary.org',
    'images-na.ssl-images-amazon.com'
  ];

  try {
    const parsedUrl = new URL(imageUrl);
    if (!allowedDomains.includes(parsedUrl.hostname)) {
      return new Response('Domain not allowed', { status: 403 });
    }
  } catch {
    return new Response('Invalid URL', { status: 400 });
  }

  // Normalize URL for consistent caching
  const normalizedUrl = normalizeImageURL(imageUrl);
  const cacheKey = `covers/${hashURL(normalizedUrl)}`;

  // Check R2 for cached image
  const cached = await env.BOOK_COVERS.get(cacheKey);

  if (cached) {
    console.log(`Image cache HIT: ${cacheKey}`);
    return resizeImage(await cached.arrayBuffer(), size, cached.httpMetadata?.contentType);
  }

  console.log(`Image cache MISS: ${cacheKey}`);

  // Cache miss - fetch from origin
  const origin = await fetch(normalizedUrl, {
    headers: { 'User-Agent': 'BooksTrack/3.0 (book-cover-proxy)' }
  });

  if (!origin.ok) {
    console.error(`Failed to fetch image from origin: ${origin.status}`);
    return new Response('Failed to fetch image', { status: 502 });
  }

  // Store in R2 for future requests
  const imageData = await origin.arrayBuffer();
  const contentType = origin.headers.get('content-type') || 'image/jpeg';

  await env.BOOK_COVERS.put(cacheKey, imageData, {
    httpMetadata: { contentType }
  });

  console.log(`Stored in R2: ${cacheKey} (${imageData.byteLength} bytes)`);

  // Return resized image
  return resizeImage(imageData, size, contentType);
}

/**
 * Hash URL for R2 key generation (consistent, collision-resistant)
 */
function hashURL(url: string): string {
  const hash = createHash('sha256');
  hash.update(url);
  return hash.digest('hex');
}

/**
 * Resize image using Cloudflare Image Resizing
 */
function resizeImage(imageData: ArrayBuffer, size: string, contentType: string): Response {
  const SIZE_MAP = {
    small: { width: 128, height: 192 },
    medium: { width: 256, height: 384 },
    large: { width: 512, height: 768 }
  };

  const dimensions = SIZE_MAP[size] || SIZE_MAP.medium;

  return new Response(imageData, {
    headers: {
      'Content-Type': contentType,
      'Cache-Control': 'public, max-age=2592000, immutable', // 30 days
      'CF-Image-Width': dimensions.width.toString(),
      'CF-Image-Height': dimensions.height.toString(),
      'CF-Image-Fit': 'scale-down'
    }
  });
}
```

**Cloudflare Services Used:**
- **R2 Storage:** Unlimited storage, $0.015/GB/month (original images)
- **Image Resizing:** Included in Workers plan (on-the-fly thumbnails)
- **CDN Edge Cache:** Automatic caching of resized images at edge (free)

**Performance Targets:**
- P95 cache hit (R2): <100ms
- P95 cache miss (origin fetch): <500ms
- Cache hit rate: >90% after 24h warmup

**File:** `src/index.js` (add route)
```javascript
import { handleImageProxy } from './handlers/image-proxy.ts';

// Add route
if (url.pathname === '/images/proxy') {
  return handleImageProxy(request, env);
}
```

**File:** `wrangler.toml` (add R2 binding)
```toml
[[r2_buckets]]
binding = "BOOK_COVERS"
bucket_name = "bookstrack-covers"
```

### 4. iOS Integration (Mandatory Proxy)

**File:** `BooksTrackerPackage/Sources/BooksTrackerFeature/Services/BookSearchAPIService.swift`

```swift
private func rewriteCoverURL(_ originalURL: String?) -> String? {
    guard let original = originalURL else { return nil }

    // Rewrite to use proxy (mandatory)
    let proxyBase = "https://books-api-proxy.jukasdrj.workers.dev/images/proxy"
    let encodedURL = original.addingPercentEncoding(withAllowedCharacters: .urlQueryAllowed) ?? original
    return "\(proxyBase)?url=\(encodedURL)&size=medium"
}
```

**Rationale for Mandatory Proxy:**
- 100% cache benefit (no direct external URLs bypass cache)
- Simpler client logic (no fallback branches)
- Single point of control for image optimization
- Backend uptime is already critical (app requires API for search)

---

## iOS Design (#217)

### 1. Performance Optimizations (3 HIGH Priority Methods)

**Problem:** Current methods load full object graphs when only counts needed. For 1,000+ book library:
- `totalBooksCount()`: Loads ~10MB of Work objects just to count them
- `reviewQueueCount()`: Fetches entire review queue to count items
- `fetchByReadingStatus()`: Loads all library works before filtering

**Solution:** Use SwiftData `fetchCount()` and optimized predicates

#### Optimization 1: `totalBooksCount()` (Line 153-155)

**Before:**
```swift
public func totalBooksCount() throws -> Int {
    return try fetchUserLibrary().count  // ❌ Loads ~10MB for count
}
```

**After:**
```swift
public func totalBooksCount() throws -> Int {
    // Count UserLibraryEntry records (each entry = 1 book in library)
    // PERFORMANCE: Uses fetchCount() - no object materialization, 10x faster
    let descriptor = FetchDescriptor<UserLibraryEntry>()
    return try modelContext.fetchCount(descriptor)
}
```

**Improvement:** 10x faster (0.5ms vs 5ms for 1000 books)

#### Optimization 2: `reviewQueueCount()` (Line 194-196)

**Before:**
```swift
public func reviewQueueCount() throws -> Int {
    return try fetchReviewQueue().count  // ❌ Calls fetchReviewQueue() which loads objects
}
```

**After:**
```swift
public func reviewQueueCount() throws -> Int {
    // PERFORMANCE: Direct database-level count with predicate
    let descriptor = FetchDescriptor<Work>(
        predicate: #Predicate { $0.reviewStatus == .needsReview }
    )
    return try modelContext.fetchCount(descriptor)
}
```

**Improvement:** 8x faster (database count vs object loading)

#### Optimization 3: `fetchByReadingStatus()` (Line 89-96)

**Before:**
```swift
public func fetchByReadingStatus(_ status: ReadingStatus) throws -> [Work] {
    let allWorks = try fetchUserLibrary()  // ❌ Loads all library Works
    return allWorks.filter { work in
        work.userLibraryEntries?.first?.readingStatus == status
    }
}
```

**After:**
```swift
public func fetchByReadingStatus(_ status: ReadingStatus) throws -> [Work] {
    // PERFORMANCE: Fetch UserLibraryEntry first (smaller dataset), then map to Works
    let descriptor = FetchDescriptor<UserLibraryEntry>(
        predicate: #Predicate { $0.readingStatus == status }
    )
    let entries = try modelContext.fetch(descriptor)

    // Map to Works (only loads needed Works, not entire library)
    return entries.compactMap { $0.work }
}
```

**Improvement:** 3-5x faster (smaller dataset to filter)

### 2. Type Safety: ReadingStatistics Struct

**Problem:** `calculateReadingStatistics()` returns unsafe `[String: Any]` dictionary
- Runtime crashes from typos: `stats["totalBook"]` (missing 's')
- Wrong type assumptions: `stats["completionRate"] as! Int` (actually Double)
- No IDE autocomplete

**Solution:** Define Codable, Sendable struct

**Add to:** `BooksTrackerPackage/Sources/BooksTrackerFeature/Repository/LibraryRepository.swift`

```swift
/// Reading statistics for Insights view
public struct ReadingStatistics: Codable, Sendable {
    public let totalBooks: Int
    public let completionRate: Double
    public let currentlyReading: Int
    public let totalPagesRead: Int

    public init(totalBooks: Int, completionRate: Double, currentlyReading: Int, totalPagesRead: Int) {
        self.totalBooks = totalBooks
        self.completionRate = completionRate
        self.currentlyReading = currentlyReading
        self.totalPagesRead = totalPagesRead
    }
}
```

**Updated Method:**
```swift
/// Calculates reading statistics (completion rate, pages read, etc.).
///
/// **Metrics:**
/// - Total books
/// - Completion rate (0.0 to 1.0)
/// - Currently reading count
/// - Total pages read
///
/// - Returns: Typed statistics struct (compile-time safe)
/// - Throws: `SwiftDataError` if query fails
public func calculateReadingStatistics() throws -> ReadingStatistics {
    let total = try totalBooksCount()
    let completion = try completionRate()
    let reading = try fetchCurrentlyReading().count

    // Calculate total pages read
    let readBooks = try fetchByReadingStatus(.read)
    let totalPages = readBooks.compactMap { work in
        work.userLibraryEntries?.first?.edition?.pageCount
    }.reduce(0, +)

    return ReadingStatistics(
        totalBooks: total,
        completionRate: completion,
        currentlyReading: reading,
        totalPagesRead: totalPages
    )
}
```

**Benefits:**
- ✅ Compile-time safety (typos caught at build time)
- ✅ IDE autocomplete (`stats.totalBooks` not `stats["totalBooks"]`)
- ✅ Type-safe access (no casting needed)
- ✅ Codable for future persistence/export
- ✅ Sendable for Swift 6 concurrency

**Update Call Sites:**

**File:** `BooksTrackerPackage/Sources/BooksTrackerFeature/Views/Insights/InsightsView.swift`

```swift
// Before
let stats = try repository.calculateReadingStatistics()
let total = stats["totalBooks"] as? Int ?? 0  // ❌ Unsafe

// After
let stats = try repository.calculateReadingStatistics()
let total = stats.totalBooks  // ✅ Type-safe
```

### 3. Testing Strategy

#### Performance Tests

**New File:** `BooksTrackerPackage/Tests/BooksTrackerFeatureTests/Repository/LibraryRepositoryPerformanceTests.swift`

```swift
import Testing
import SwiftData
@testable import BooksTrackerFeature

@MainActor
struct LibraryRepositoryPerformanceTests {

    @Test func totalBooksCount_performance_1000books() async throws {
        let (repository, context) = makeTestRepository()

        // Create 1000 test books
        for i in 1...1000 {
            let work = Work(title: "Book \(i)", authors: [])
            context.insert(work)
            let entry = UserLibraryEntry(work: work, readingStatus: .toRead)
            context.insert(entry)
        }

        // Measure performance
        let startTime = ContinuousClock.now
        let count = try repository.totalBooksCount()
        let elapsed = ContinuousClock.now - startTime

        #expect(count == 1000)
        #expect(elapsed < .milliseconds(10))  // Must be <10ms for 1000 books
    }

    @Test func reviewQueueCount_performance() async throws {
        let (repository, context) = makeTestRepository()

        // Create 500 books, 100 need review
        for i in 1...500 {
            let work = Work(title: "Book \(i)", authors: [])
            work.reviewStatus = (i <= 100) ? .needsReview : .reviewed
            context.insert(work)
        }

        let startTime = ContinuousClock.now
        let count = try repository.reviewQueueCount()
        let elapsed = ContinuousClock.now - startTime

        #expect(count == 100)
        #expect(elapsed < .milliseconds(5))  // Must be <5ms
    }

    @Test func fetchByReadingStatus_performance() async throws {
        let (repository, context) = makeTestRepository()

        // Create 1000 books with mixed statuses
        for i in 1...1000 {
            let work = Work(title: "Book \(i)", authors: [])
            context.insert(work)
            let status: ReadingStatus = (i % 4 == 0) ? .reading : .toRead
            let entry = UserLibraryEntry(work: work, readingStatus: status)
            context.insert(entry)
        }

        let startTime = ContinuousClock.now
        let reading = try repository.fetchByReadingStatus(.reading)
        let elapsed = ContinuousClock.now - startTime

        #expect(reading.count == 250)
        #expect(elapsed < .milliseconds(20))  // Must be <20ms
    }

    private func makeTestRepository() -> (LibraryRepository, ModelContext) {
        let config = ModelConfiguration(isStoredInMemoryOnly: true)
        let container = try! ModelContainer(
            for: Work.self, Edition.self, Author.self, UserLibraryEntry.self,
            configurations: config
        )
        let context = ModelContext(container)
        let repository = LibraryRepository(modelContext: context)
        return (repository, context)
    }
}
```

#### DTO Tests

**New File:** `cloudflare-workers/api-worker/tests/canonical-dto-validation.test.ts`

```typescript
import { describe, test, expect } from 'vitest';
import type { WorkDTO, EditionDTO, AuthorDTO } from '../src/types/canonical';

describe('Canonical DTO Schema Validation', () => {
  test('WorkDTO has all required fields', () => {
    const work: WorkDTO = {
      olid: 'OL123W',
      title: 'The Hobbit',
      authors: [],
      editions: [],
      subjects: [],
      coverImages: {
        small: null,
        medium: null,
        large: null
      },
      primaryProvider: 'google-books',
      contributors: ['google-books'],
      synthetic: false
    };

    expect(work.olid).toBe('OL123W');
    expect(work.title).toBe('The Hobbit');
  });

  test('EditionDTO supports multiple ISBNs', () => {
    const edition: EditionDTO = {
      isbn13: ['9780547928227', '9780547928234'],
      isbn10: ['0547928220'],
      title: 'The Hobbit',
      publisher: 'Houghton Mifflin',
      publishDate: '2012',
      pageCount: 300,
      coverImages: {
        small: null,
        medium: null,
        large: null
      }
    };

    expect(edition.isbn13).toHaveLength(2);
    expect(edition.isbn10).toHaveLength(1);
  });
});
```

**Enhanced:** `BooksTrackerPackage/Tests/BooksTrackerFeatureTests/API/CanonicalAPIResponseTests.swift`

```swift
// Add edge case tests
@Test func editionDTO_missingISBN_decodesSuccessfully() async throws {
    let json = """
    {
      "title": "Unknown Book",
      "publisher": "Unknown",
      "publishDate": "2020"
    }
    """
    let edition = try JSONDecoder().decode(EditionDTO.self, from: json.data(using: .utf8)!)

    #expect(edition.isbn13 == nil)
    #expect(edition.isbn10 == nil)
    #expect(edition.title == "Unknown Book")
}

@Test func workDTO_nullAuthors_decodesAsEmptyArray() async throws {
    let json = """
    {
      "olid": "OL123W",
      "title": "Anonymous Work",
      "authors": null
    }
    """
    let work = try JSONDecoder().decode(WorkDTO.self, from: json.data(using: .utf8)!)

    #expect(work.authors?.isEmpty == true)
}
```

---

## Deployment & Success Metrics

### Deployment Strategy

#### Phase 1: Backend (#197 + #147)

```bash
# From backend worktree
cd cloudflare-workers/api-worker

# Run tests
npm run test

# Deploy to production
npx wrangler deploy

# Monitor logs for errors
npx wrangler tail --search "ERROR"
```

**Validation Checklist:**
- [ ] All TypeScript tests pass
- [ ] Deployment succeeds without errors
- [ ] `/images/proxy` endpoint responds (test with sample URL)
- [ ] Search endpoints use normalized cache keys (check logs)
- [ ] No increase in error rate (monitor for 1 hour)

#### Phase 2: iOS (#217)

```bash
# From iOS worktree
/build                 # Build validation
/test                  # Run Swift Testing suite (including performance tests)
/sim                   # Manual testing in simulator
```

**Validation Checklist:**
- [ ] Zero warnings, zero errors
- [ ] Performance tests pass (10x improvement confirmed)
- [ ] InsightsView displays stats correctly (uses ReadingStatistics struct)
- [ ] Image proxy URLs load in search results
- [ ] No regressions in existing functionality

### Success Metrics

| Metric | Baseline | Target | How to Measure |
|--------|----------|--------|----------------|
| **Backend cache hit rate** | 60-70% | 75-90% | Analytics Engine dashboard |
| **Image load time (P95 cache hit)** | ~800ms | <100ms | CloudWatch/logs |
| **Image load time (P95 cache miss)** | ~800ms | <500ms | CloudWatch/logs |
| **Image cache hit rate** | 0% (no cache) | >90% | R2 analytics |
| **iOS totalBooksCount()** | ~5ms (1000 books) | <0.5ms | LibraryRepositoryPerformanceTests |
| **iOS reviewQueueCount()** | ~3ms | <0.4ms | Performance tests |
| **iOS fetchByReadingStatus()** | ~8ms | <2ms | Performance tests |
| **Type safety incidents** | 2-3/month | 0 | Crash reports (TestFlight) |

### Rollback Plan

**Backend:**
```bash
npx wrangler rollback
```
Reverts to previous deployment. R2 bucket remains (no data loss).

**iOS:**
```bash
git revert <commit-sha>
/gogo  # Rebuild and deploy
```

---

## Files Modified Summary

### Backend (12 files)

**New Files:**
- `src/utils/normalization.ts` - Shared normalization utilities
- `src/handlers/image-proxy.ts` - Image proxy endpoint
- `tests/normalization.test.ts` - Normalization unit tests
- `tests/canonical-dto-validation.test.ts` - DTO schema tests
- `tests/normalization-consistency.test.ts` - Google Books → Canonical tests
- `tests/genre-mapping.test.ts` - Genre normalization tests

**Modified Files:**
- `src/handlers/v1/search-title.ts` - Add title normalization
- `src/handlers/v1/search-isbn.ts` - Add ISBN normalization
- `src/handlers/v1/search-advanced.ts` - Add title + author normalization
- `src/services/enrichment.ts` - Normalize before cache lookup
- `src/index.js` - Add `/images/proxy` route
- `wrangler.toml` - Add R2 bucket binding

### iOS (5 files)

**New Files:**
- `BooksTrackerPackage/Tests/BooksTrackerFeatureTests/Repository/LibraryRepositoryPerformanceTests.swift`

**Modified Files:**
- `BooksTrackerPackage/Sources/BooksTrackerFeature/Repository/LibraryRepository.swift` - 3 optimizations + ReadingStatistics struct
- `BooksTrackerPackage/Tests/BooksTrackerFeatureTests/API/CanonicalAPIResponseTests.swift` - Add edge case tests
- `BooksTrackerPackage/Sources/BooksTrackerFeature/Services/BookSearchAPIService.swift` - Rewrite cover URLs to use proxy
- `BooksTrackerPackage/Sources/BooksTrackerFeature/Views/Insights/InsightsView.swift` - Use ReadingStatistics struct

---

## Risk Assessment

### Low Risks
- Normalization logic is pure functions (easy to test)
- Performance optimizations are SwiftData best practices
- Image proxy uses proven Cloudflare services (R2, Image Resizing)

### Medium Risks
- **Cache invalidation:** Normalization changes cache keys (existing cache misses initially)
  - **Mitigation:** Cache TTLs are 6h-7d, will repopulate naturally
- **Image proxy domain allowlist:** May need to add new domains if new providers added
  - **Mitigation:** Clear error messages, easy to add domains

### Monitoring

**Backend:**
- Cache hit rate via Analytics Engine
- Image proxy error rate (502s from origin)
- R2 storage growth

**iOS:**
- TestFlight crash reports (type safety validation)
- Performance test results in CI (when GitHub Actions supports Swift 6.2)

---

## Future Enhancements (Out of Scope)

**Not included in this design:**
- Cache warming based on trending books (issue #198)
- Persistent DTOMapper cache with pruning (issue #199)
- ISBNdb dependency removal (issue #201)

These are tracked separately and do not block this work.

---

## References

- **Issue #197:** [Cache Key Normalization](https://github.com/jukasdrj/books-tracker-v1/issues/197)
- **Issue #147:** [Edge Caching for Images](https://github.com/jukasdrj/books-tracker-v1/issues/147)
- **Issue #217:** [Performance Optimizations + DTO Tests](https://github.com/jukasdrj/books-tracker-v1/issues/217)
- **Related PR #215:** [Repository Pattern + iOS Data Layer](https://github.com/jukasdrj/books-tracker-v1/pull/215)

---

**Design Status:** ✅ Approved
**Next Step:** Set up worktree for backend work (#197 + #147)
